"""
Model wrappers for training: generic DiT transformer (LoRA, full finetune).
"""

from .transformer_wrapper import TransformerWrapper

__all__ = ["TransformerWrapper"]
