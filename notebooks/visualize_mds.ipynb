{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MDS and Latents Visualization\n",
        "\n",
        "Read MDS shards (prepare output) and mds_latents (precompute output). Decode precomputed latents via FLUX VAE to visualize reconstructed images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from diffusers import AutoencoderKLFlux2\n",
        "from matplotlib import pyplot as plt\n",
        "from streaming import StreamingDataset\n",
        "\n",
        "# Flat MDS dirs: prepare output and precompute output\n",
        "MDS_DIR = \"./mds\"\n",
        "LATENTS_DIR = \"./mds_latents_flux2\""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ab82e7e9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize MDS (prepare output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def visualize_mds(mds_dir: str, num_samples: int = 4):\n",
        "    ds = StreamingDataset(local=mds_dir, batch_size=1, shuffle=False)\n",
        "    n = min(num_samples, len(ds))\n",
        "    fig, axes = plt.subplots(1, n, figsize=(4 * n, 4))\n",
        "    if n == 1:\n",
        "        axes = [axes]\n",
        "    for i in range(n):\n",
        "        sample = ds[i]\n",
        "        img = sample[\"image\"]\n",
        "        if not isinstance(img, np.ndarray):\n",
        "            img = np.array(img.convert(\"RGB\")) if hasattr(img, \"convert\") else np.array(img)\n",
        "        axes[i].imshow(img)\n",
        "        cap = sample.get(\"caption\", \"\")\n",
        "        axes[i].set_title(cap[:60] + \"...\" if len(cap) > 60 else cap, fontsize=8)\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_mds(MDS_DIR)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "056dcda2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize mds_latents (VAE decode)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def bytes_to_latent(data: bytes, resolution: int = 512, latent_channels: int = 16) -> torch.Tensor:\n",
        "    h = w = resolution // 8\n",
        "    arr = np.frombuffer(data, dtype=np.float16)\n",
        "    return torch.from_numpy(arr.reshape(latent_channels, h, w).astype(np.float32))\n",
        "\n",
        "\n",
        "RESOLUTION = 512\n",
        "LATENT_KEY = f\"latents_{RESOLUTION}\"\n",
        "MODEL_ID = \"black-forest-labs/FLUX.2-klein-base-4B\""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "df8dc30e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "vae = AutoencoderKLFlux2.from_pretrained(MODEL_ID, subfolder=\"vae\").to(device).eval()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f8ba1a16"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def visualize_latents(latents_dir: str, num_samples: int = 4):\n",
        "    ds = StreamingDataset(local=latents_dir, batch_size=1, shuffle=False)\n",
        "    n = min(num_samples, len(ds))\n",
        "    fig, axes = plt.subplots(1, n, figsize=(4 * n, 4))\n",
        "    if n == 1:\n",
        "        axes = [axes]\n",
        "    for i in range(n):\n",
        "        sample = ds[i]\n",
        "        lat_bytes = sample[LATENT_KEY]\n",
        "        lat = bytes_to_latent(lat_bytes, RESOLUTION).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            decoded = vae.decode(lat).sample\n",
        "        img = decoded[0].permute(1, 2, 0).cpu().numpy()\n",
        "        img = (img / 2 + 0.5).clip(0, 1)\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(sample.get(\"caption\", \"\")[:60] + \"...\" if len(str(sample.get(\"caption\", \"\"))) > 60 else sample.get(\"caption\", \"\"), fontsize=8)\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_latents(LATENTS_DIR)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "19117bf4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}